{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# Check out https://www.tensorflow.org/get_started/mnist/beginners for\n",
    "# more information about the mnist dataset\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "tf.set_random_seed(777)  # reproducibility\n",
    "nb_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-00d5cb141cdc>:16: arg_max (from tensorflow.python.ops.gen_math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `argmax` instead\n"
     ]
    }
   ],
   "source": [
    "# MNIST data image of shape 28 * 28 = 784\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 0 - 9 digits recognition = 10 classes\n",
    "Y = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([784, nb_classes]))\n",
    "b = tf.Variable(tf.random_normal([nb_classes]))\n",
    "\n",
    "# Hypothesis (using softmax)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)\n",
    "\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Test model\n",
    "is_correct = tf.equal(tf.arg_max(hypothesis, 1), tf.arg_max(Y, 1))\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "# parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 2.835604621\n",
      "Epoch: 0002 cost = 1.060486327\n",
      "Epoch: 0003 cost = 0.836493282\n",
      "Epoch: 0004 cost = 0.733177067\n",
      "Epoch: 0005 cost = 0.669140394\n",
      "Epoch: 0006 cost = 0.624411475\n",
      "Epoch: 0007 cost = 0.590043233\n",
      "Epoch: 0008 cost = 0.563619190\n",
      "Epoch: 0009 cost = 0.541243046\n",
      "Epoch: 0010 cost = 0.522313855\n",
      "Epoch: 0011 cost = 0.506151044\n",
      "Epoch: 0012 cost = 0.492651495\n",
      "Epoch: 0013 cost = 0.479880336\n",
      "Epoch: 0014 cost = 0.468596220\n",
      "Epoch: 0015 cost = 0.458903052\n",
      "Learning finished\n",
      "Accuracy:  0.8957\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    # Initialize TensorFlow variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # Training cycle\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            c, _ = sess.run([cost, optimizer], feed_dict={\n",
    "                            X: batch_xs, Y: batch_ys})\n",
    "            avg_cost += c / total_batch\n",
    "\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "    print(\"Learning finished\")\n",
    "\n",
    "    # Test the model using test sets\n",
    "    print(\"Accuracy: \", accuracy.eval(session=sess, feed_dict={\n",
    "          X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "    # Get one and predict\n",
    "    r = random.randint(0, mnist.test.num_examples - 1)\n",
    "    print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "    print(\"Prediction: \", sess.run(\n",
    "        tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "    plt.imshow(\n",
    "        mnist.test.images[r:r + 1].reshape(28, 28),\n",
    "        cmap='Greys',\n",
    "        interpolation='nearest')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-6ef0ef0df188>:24: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0001 cost = 156.285055369\n",
      "Epoch: 0002 cost = 38.009097578\n",
      "Epoch: 0003 cost = 23.581135208\n",
      "Epoch: 0004 cost = 16.381305880\n",
      "Epoch: 0005 cost = 11.720081147\n",
      "Epoch: 0006 cost = 8.693742665\n",
      "Epoch: 0007 cost = 6.373194514\n",
      "Epoch: 0008 cost = 4.813120228\n",
      "Epoch: 0009 cost = 3.683871269\n",
      "Epoch: 0010 cost = 2.709823304\n",
      "Epoch: 0011 cost = 1.975161846\n",
      "Epoch: 0012 cost = 1.553065263\n",
      "Epoch: 0013 cost = 1.189576570\n",
      "Epoch: 0014 cost = 0.932938319\n",
      "Epoch: 0015 cost = 0.692586018\n",
      "Learning Finished!\n",
      "Accuracy: 0.9432\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "W1 = tf.Variable(tf.random_normal([784, 256]))\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256]))\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10]))\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xavier 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-81fb04f55dfd>:28: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0001 cost = 0.305624656\n",
      "Epoch: 0002 cost = 0.111410543\n",
      "Epoch: 0003 cost = 0.072243954\n",
      "Epoch: 0004 cost = 0.052469312\n",
      "Epoch: 0005 cost = 0.038837223\n",
      "Epoch: 0006 cost = 0.028806800\n",
      "Epoch: 0007 cost = 0.024579718\n",
      "Epoch: 0008 cost = 0.019228536\n",
      "Epoch: 0009 cost = 0.016849895\n",
      "Epoch: 0010 cost = 0.014733180\n",
      "Epoch: 0011 cost = 0.010823507\n",
      "Epoch: 0012 cost = 0.013942914\n",
      "Epoch: 0013 cost = 0.009909121\n",
      "Epoch: 0014 cost = 0.009308566\n",
      "Epoch: 0015 cost = 0.011146484\n",
      "Learning Finished!\n",
      "Accuracy: 0.979\n",
      "Label:  [1]\n",
      "Prediction:  [1]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 256], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([256]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[256, 256],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([256]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[256, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b3\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "          reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "tf.set_random_seed(777)  # reproducibilityplt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-07c36062bd36>:39: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "Epoch: 0001 cost = 0.296692585\n",
      "Epoch: 0002 cost = 0.105126909\n",
      "Epoch: 0003 cost = 0.070916030\n",
      "Epoch: 0004 cost = 0.054094118\n",
      "Epoch: 0005 cost = 0.041283473\n",
      "Epoch: 0006 cost = 0.035529787\n",
      "Epoch: 0007 cost = 0.028978590\n",
      "Epoch: 0008 cost = 0.025732956\n",
      "Epoch: 0009 cost = 0.025104730\n",
      "Epoch: 0010 cost = 0.018081026\n",
      "Epoch: 0011 cost = 0.020960107\n",
      "Epoch: 0012 cost = 0.017482232\n",
      "Epoch: 0013 cost = 0.015934724\n",
      "Epoch: 0014 cost = 0.016768658\n",
      "Epoch: 0015 cost = 0.011958182\n",
      "Learning Finished!\n",
      "Accuracy: 0.9787\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1]}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 0.466554790\n",
      "Epoch: 0002 cost = 0.171860894\n",
      "Epoch: 0003 cost = 0.131535071\n",
      "Epoch: 0004 cost = 0.109510833\n",
      "Epoch: 0005 cost = 0.092171306\n",
      "Epoch: 0006 cost = 0.086876077\n",
      "Epoch: 0007 cost = 0.075348697\n",
      "Epoch: 0008 cost = 0.069156599\n",
      "Epoch: 0009 cost = 0.063560429\n",
      "Epoch: 0010 cost = 0.060149611\n",
      "Epoch: 0011 cost = 0.055868338\n",
      "Epoch: 0012 cost = 0.053575429\n",
      "Epoch: 0013 cost = 0.052515444\n",
      "Epoch: 0014 cost = 0.048694492\n",
      "Epoch: 0015 cost = 0.047672914\n",
      "Learning Finished!\n",
      "Accuracy: 0.9808\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "# parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# dropout (keep_prob) rate  0.7 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# weights & bias for nn layers\n",
    "# http://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "W1 = tf.get_variable(\"W1\", shape=[784, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.random_normal([512]))\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1) + b1)\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "\n",
    "W2 = tf.get_variable(\"W2\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b2 = tf.Variable(tf.random_normal([512]))\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2) + b2)\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "\n",
    "W3 = tf.get_variable(\"W3\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b3 = tf.Variable(tf.random_normal([512]))\n",
    "L3 = tf.nn.relu(tf.matmul(L2, W3) + b3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "\n",
    "W4 = tf.get_variable(\"W4\", shape=[512, 512],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([512]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "\n",
    "W5 = tf.get_variable(\"W5\", shape=[512, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L4, W5) + b5\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].\n",
    "           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.386793246\n",
      "[Epoch:    2] cost = 0.330950979\n",
      "[Epoch:    3] cost = 0.320470439\n",
      "[Epoch:    4] cost = 0.316463517\n",
      "[Epoch:    5] cost = 0.311451766\n",
      "[Epoch:    6] cost = 0.310081003\n",
      "[Epoch:    7] cost = 0.307341582\n",
      "[Epoch:    8] cost = 0.305706706\n",
      "[Epoch:    9] cost = 0.305043533\n",
      "[Epoch:   10] cost = 0.304686281\n",
      "[Epoch:   11] cost = 0.303569461\n",
      "[Epoch:   12] cost = 0.303118331\n",
      "[Epoch:   13] cost = 0.303154411\n",
      "[Epoch:   14] cost = 0.301386342\n",
      "[Epoch:   15] cost = 0.301564581\n",
      "Learning Finished!\n",
      "Accuracy: 0.9837\n",
      "Label:  [7]\n",
      "Prediction:  [7]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.contrib.layers import fully_connected, batch_norm, dropout\n",
    "from tensorflow.contrib.framework import arg_scope\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.01  # we can use large learning rate using Batch Normalization\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "keep_prob = 0.7\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "train_mode = tf.placeholder(tf.bool, name='train_mode')\n",
    "\n",
    "# layer output size\n",
    "hidden_output_size = 512\n",
    "final_output_size = 10\n",
    "\n",
    "xavier_init = tf.contrib.layers.xavier_initializer()\n",
    "bn_params = {\n",
    "    'is_training': train_mode,\n",
    "    'decay': 0.9,\n",
    "    'updates_collections': None\n",
    "}\n",
    "\n",
    "# We can build short code using 'arg_scope' to avoid duplicate code\n",
    "# same function with different arguments\n",
    "with arg_scope([fully_connected],\n",
    "               activation_fn=tf.nn.relu,\n",
    "               weights_initializer=xavier_init,\n",
    "               biases_initializer=None,\n",
    "               normalizer_fn=batch_norm,\n",
    "               normalizer_params=bn_params\n",
    "               ):\n",
    "    hidden_layer1 = fully_connected(X, hidden_output_size, scope=\"h1\")\n",
    "    h1_drop = dropout(hidden_layer1, keep_prob, is_training=train_mode)\n",
    "    hidden_layer2 = fully_connected(h1_drop, hidden_output_size, scope=\"h2\")\n",
    "    h2_drop = dropout(hidden_layer2, keep_prob, is_training=train_mode)\n",
    "    hidden_layer3 = fully_connected(h2_drop, hidden_output_size, scope=\"h3\")\n",
    "    h3_drop = dropout(hidden_layer3, keep_prob, is_training=train_mode)\n",
    "    hidden_layer4 = fully_connected(h3_drop, hidden_output_size, scope=\"h4\")\n",
    "    h4_drop = dropout(hidden_layer4, keep_prob, is_training=train_mode)\n",
    "    hypothesis = fully_connected(h4_drop, final_output_size, activation_fn=None, scope=\"hypothesis\")\n",
    "\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=hypothesis, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict_train = {X: batch_xs, Y: batch_ys, train_mode: True}\n",
    "        feed_dict_cost = {X: batch_xs, Y: batch_ys, train_mode: False}\n",
    "        opt = sess.run(optimizer, feed_dict=feed_dict_train)\n",
    "        c = sess.run(cost, feed_dict=feed_dict_cost)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print(\"[Epoch: {:>4}] cost = {:>.9}\".format(epoch + 1, avg_cost))\n",
    "    #print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, train_mode: False}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(hypothesis, 1), feed_dict={X: mnist.test.images[r:r + 1], train_mode: False}))\n",
    "\n",
    "plt.imshow(mnist.test.images[r:r + 1].reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
